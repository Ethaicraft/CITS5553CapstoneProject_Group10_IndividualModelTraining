# -*- coding: utf-8 -*-
"""DistilBERT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VxvumwLOAywAcPO1E2d4VPE4GBfnvJMC

# **DistilBERT**

# Install necessary libraries
"""

!pip install transformers datasets scikit-learn torchinfo matplotlib seaborn

"""Import required libraries"""

import torch
from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments
from datasets import Dataset
from sklearn.model_selection import train_test_split
from torchinfo import summary
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

"""upload the dataset"""

#  Upload the dataset
from google.colab import files
uploaded = files.upload()

"""# Dataset： Xstest

## load and prepare the dataset Xstest
"""

#  Load the dataset
train_df = pd.read_csv('xstest_train_clean.csv')
test_df = pd.read_csv('xstest_test_clean.csv')

# Display basic data information
print(train_df.head())
print(test_df.head())

"""Split the data into training, validation, and test sets"""

X = train_df['prompt']
y = train_df['label']
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

"""Tokenize the train, validation, and test data"""

tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')
train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=16)
val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=16)
test_encodings = tokenizer(test_df['prompt'].tolist(), truncation=True, padding=True, max_length=16)

"""Create PyTorch datasets"""

train_dataset = Dataset.from_dict({'input_ids': train_encodings['input_ids'],
                                   'attention_mask': train_encodings['attention_mask'],
                                   'labels': y_train.tolist()})
val_dataset = Dataset.from_dict({'input_ids': val_encodings['input_ids'],
                                 'attention_mask': val_encodings['attention_mask'],
                                 'labels': y_val.tolist()})
test_dataset = Dataset.from_dict({'input_ids': test_encodings['input_ids'],
                                  'attention_mask': test_encodings['attention_mask'],
                                  'labels': test_df['label'].tolist()})

"""## Load pretrained DistilBERT model"""

model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)

"""Freeze 50% of the top layers for fine-tuning"""

for param in model.distilbert.transformer.layer[:3]:  # Freezing the first 3 layers out of 6 (50%)
    for p in param.parameters():
        p.requires_grad = False

"""print the model summary"""

import torch
from torchinfo import summary

# Ensure the model is on the correct device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Create a dummy input with the correct tensor type (LongTensor)
dummy_input = torch.randint(0, tokenizer.vocab_size, (1, 40), dtype=torch.long).to(device)

# Print the model summary
summary(model, input_data=dummy_input)

"""set training arguments"""

# Set training arguments
training_args = TrainingArguments(
    output_dir='./results',
    evaluation_strategy="epoch",
    logging_strategy="epoch",  # Enable logging for each epoch to track training loss
    logging_steps=10,  # Log every 10 steps (or adjust as needed)
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir='./logs',
)

"""Define metrics for evaluation"""

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')
    acc = accuracy_score(labels, preds)
    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

"""## Model training"""

# Initialize Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics
)

# Train the model
trainer.train()

"""## Save the model"""

# Save the trained model
model.save_pretrained("DistilBERT_xstest_full")

"""Reload the model"""

# Load the saved model (optional step)
loaded_model = DistilBertForSequenceClassification.from_pretrained("DistilBERT_xstest_full")

"""## Evaluate the model on the test set and generate results"""

# Evaluate the model on the test set
results = trainer.evaluate(test_dataset)

# Print evaluation results
print(f"Test set results: {results}")

"""Generate confusion matrix and classification report"""

from sklearn.metrics import classification_report, confusion_matrix

y_true = test_df['label']
y_pred = torch.from_numpy(trainer.predict(test_dataset).predictions).argmax(dim=1)

cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Plot the Confusion Matrix as a heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')
plt.show()

print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Non-Toxic', 'Toxic']))

"""## Inference with sample texts"""

# Inference with sample texts
texts = ["Good morning!", "You are a terrible person."]
inference_encodings = tokenizer(texts, truncation=True, padding=True, return_tensors='pt')

# Ensure the model is in evaluation mode
model.eval()

# Perform inference
with torch.no_grad():
    outputs = model(**inference_encodings)
    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)

# Print predictions
labels = ['Non-Toxic', 'Toxic']
predicted_labels = [labels[pred] for pred in predictions]

for text, label in zip(texts, predicted_labels):
    print(f"Text: {text} | Predicted label: {label}")

"""## Hyperparameter Tuning"""

from transformers import Trainer, TrainingArguments
import matplotlib.pyplot as plt

# List of learning rates to try
learning_rates = [5e-5, 3e-5, 2e-5]

# Dictionary to store evaluation results for each learning rate
results_dict = {}

# Reduce the dataset size for faster experimentation
small_train_dataset = train_dataset.select(range(200))  # Select the first 200 samples for training
small_val_dataset = val_dataset.select(range(40))       # Select the first 40 samples for validation
small_test_dataset = test_dataset.select(range(40))     # Select the first 40 samples for testing

for lr in learning_rates:
    print(f"Training with learning rate: {lr}")

    # Adjust the learning rate and number of epochs for quicker training
    training_args = TrainingArguments(
        output_dir='./results',
        evaluation_strategy="epoch",
        save_strategy="epoch",  # Set save strategy to match evaluation strategy
        logging_strategy="steps",
        logging_steps=10,
        learning_rate=lr,
        per_device_train_batch_size=8,
        per_device_eval_batch_size=8,
        num_train_epochs=3,
        weight_decay=0.01,
        logging_dir='./logs',
        load_best_model_at_end=True,  # Still keep this to load the best model
        metric_for_best_model="eval_loss"  # Define the metric to monitor
    )

    # Set up the trainer without early stopping
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=small_train_dataset,
        eval_dataset=small_val_dataset,
        compute_metrics=compute_metrics
    )

    # Train the model
    trainer.train()

    # Evaluate the model
    eval_results = trainer.evaluate(small_test_dataset)

    # Save the evaluation results in the dictionary
    results_dict[lr] = eval_results
    print(f"Results with learning rate {lr}: {eval_results}")

# Plot learning rates vs accuracy
accuracies = [results_dict[lr]['eval_accuracy'] for lr in learning_rates]
plt.plot(learning_rates, accuracies, marker='o')
plt.xlabel('Learning Rate')
plt.ylabel('Accuracy')
plt.title('Accuracy vs Learning Rate')
plt.xscale('log')  # Use log scale for the learning rate
plt.show()

"""## pre-trained model test result without training for comparison"""

# Load the pretrained model
pretrained_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')

# Ensure the model is in evaluation mode
pretrained_model.eval()

# Tokenize the test data
test_encodings = tokenizer(test_df['prompt'].tolist(), truncation=True, padding=True, max_length=16)

# Create the test dataset
test_dataset = Dataset.from_dict({
    'input_ids': test_encodings['input_ids'],
    'attention_mask': test_encodings['attention_mask'],
    'labels': test_df['label'].tolist()
})

# Perform inference on the test dataset using the pretrained model
predictions = []
with torch.no_grad():
    for i in range(len(test_dataset)):
        inputs = {
            'input_ids': torch.tensor(test_encodings['input_ids'][i]).unsqueeze(0),
            'attention_mask': torch.tensor(test_encodings['attention_mask'][i]).unsqueeze(0)
        }
        outputs = pretrained_model(**inputs)
        pred = torch.argmax(outputs.logits, dim=-1)
        predictions.append(pred.item())

# Generate the confusion matrix and classification report
y_true = test_df['label']
y_pred = predictions

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Plot the Confusion Matrix as a heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')
plt.show()

# Classification report
print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Non-Toxic', 'Toxic']))

"""# Dataset: HatespeachDetection

## load and prepare the dataset HateSpeachDetection
"""

# Load the dataset
train_df = pd.read_csv('HateSpeechDetection_train_Clean.csv')
test_df = pd.read_csv('HateSpeechDetection_test_Clean.csv')

# Display basic data information
print(train_df.head())
print(test_df.head())

"""Split the data into training, validation, and test sets"""

X = train_df['prompt']
y = train_df['label']
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

"""Tokenize the train, validation, and test data"""

tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')
train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=40)
val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=40)
test_encodings = tokenizer(test_df['prompt'].tolist(), truncation=True, padding=True, max_length=40)

"""Create PyTorch datasets"""

train_dataset = Dataset.from_dict({'input_ids': train_encodings['input_ids'],
                                   'attention_mask': train_encodings['attention_mask'],
                                   'labels': y_train.tolist()})
val_dataset = Dataset.from_dict({'input_ids': val_encodings['input_ids'],
                                 'attention_mask': val_encodings['attention_mask'],
                                 'labels': y_val.tolist()})
test_dataset = Dataset.from_dict({'input_ids': test_encodings['input_ids'],
                                  'attention_mask': test_encodings['attention_mask'],
                                  'labels': test_df['label'].tolist()})

"""## Load pretrained DistilBERT model"""

model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)

"""Freeze 50% of the top layers for fine-tuning"""

for param in model.distilbert.transformer.layer[:3]:  # Freezing the first 3 layers out of 6 (50%)
    for p in param.parameters():
        p.requires_grad = False

"""print the model summary"""

import torch
from torchinfo import summary

# Ensure the model is on the correct device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Create a dummy input with the correct tensor type (LongTensor)
dummy_input = torch.randint(0, tokenizer.vocab_size, (1, 40), dtype=torch.long).to(device)

# Print the model summary
summary(model, input_data=dummy_input)

"""set training arguments"""

# Set training arguments
training_args = TrainingArguments(
    output_dir='./results',
    evaluation_strategy="epoch",
    logging_strategy="epoch",  # Enable logging for each epoch to track training loss
    logging_steps=10,  # Log every 10 steps (or adjust as needed)
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir='./logs',
)

"""Define metrics for evaluation"""

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')
    acc = accuracy_score(labels, preds)
    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

"""## Model training"""

# Initialize Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics
)

# Train the model
trainer.train()

"""## Save the model"""

# Save the trained model
model.save_pretrained("DistilBERT_HateSpeachDetection_full")

"""Reload the model"""

# Load the saved model (optional step)
loaded_model = DistilBertForSequenceClassification.from_pretrained("DistilBERT_HateSpeachDetection_full")

"""## Evaluate the model on the test set and generate results"""

# Evaluate the model on the test set
results = trainer.evaluate(test_dataset)

# Print evaluation results
print(f"Test set results: {results}")

"""Generate confusion matrix and classification report"""

from sklearn.metrics import classification_report, confusion_matrix

y_true = test_df['label']
y_pred = torch.from_numpy(trainer.predict(test_dataset).predictions).argmax(dim=1)

cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Plot the Confusion Matrix as a heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')
plt.show()

print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Non-Toxic', 'Toxic']))

"""## Inference with sample texts"""

# Inference with sample texts
texts = ["I am very hundsome!", "You are a terrible person."]
inference_encodings = tokenizer(texts, truncation=True, padding=True, return_tensors='pt')

# Ensure the model is in evaluation mode
model.eval()

# Perform inference
with torch.no_grad():
    outputs = model(**inference_encodings)
    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)

# Print predictions
labels = ['Non-Toxic', 'Toxic']
predicted_labels = [labels[pred] for pred in predictions]

for text, label in zip(texts, predicted_labels):
    print(f"Text: {text} | Predicted label: {label}")

"""## Hyperparameter Tuning"""

from transformers import Trainer, TrainingArguments
import matplotlib.pyplot as plt

# List of learning rates to try
learning_rates = [5e-5, 3e-5, 2e-5]

# Dictionary to store evaluation results for each learning rate
results_dict = {}

# Reduce the dataset size for faster experimentation
small_train_dataset = train_dataset.select(range(300))  # Select the first 500 samples for training
small_val_dataset = val_dataset.select(range(60))       # Select the first 100 samples for validation
small_test_dataset = test_dataset.select(range(60))     # Select the first 100 samples for testing

for lr in learning_rates:
    print(f"Training with learning rate: {lr}")

    # Adjust the learning rate and number of epochs for quicker training
    training_args = TrainingArguments(
        output_dir='./results',
        evaluation_strategy="epoch",
        save_strategy="epoch",  # Set save strategy to match evaluation strategy
        logging_strategy="steps",
        logging_steps=10,
        learning_rate=lr,
        per_device_train_batch_size=8,
        per_device_eval_batch_size=8,
        num_train_epochs=3,
        weight_decay=0.01,
        logging_dir='./logs',
        load_best_model_at_end=True,  # Still keep this to load the best model
        metric_for_best_model="eval_loss"  # Define the metric to monitor
    )

    # Set up the trainer without early stopping
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=small_train_dataset,
        eval_dataset=small_val_dataset,
        compute_metrics=compute_metrics
    )

    # Train the model
    trainer.train()

    # Evaluate the model
    eval_results = trainer.evaluate(small_test_dataset)

    # Save the evaluation results in the dictionary
    results_dict[lr] = eval_results
    print(f"Results with learning rate {lr}: {eval_results}")

# Plot learning rates vs accuracy
accuracies = [results_dict[lr]['eval_accuracy'] for lr in learning_rates]
plt.plot(learning_rates, accuracies, marker='o')
plt.xlabel('Learning Rate')
plt.ylabel('Accuracy')
plt.title('Accuracy vs Learning Rate')
plt.xscale('log')  # Use log scale for the learning rate
plt.show()

"""## pre-trained model test result without training for comparison"""

# Load the pretrained model
pretrained_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')

# Ensure the model is in evaluation mode
pretrained_model.eval()

# Tokenize the test data
test_encodings = tokenizer(test_df['prompt'].tolist(), truncation=True, padding=True, max_length=16)

# Create the test dataset
test_dataset = Dataset.from_dict({
    'input_ids': test_encodings['input_ids'],
    'attention_mask': test_encodings['attention_mask'],
    'labels': test_df['label'].tolist()
})

# Perform inference on the test dataset using the pretrained model
predictions = []
with torch.no_grad():
    for i in range(len(test_dataset)):
        inputs = {
            'input_ids': torch.tensor(test_encodings['input_ids'][i]).unsqueeze(0),
            'attention_mask': torch.tensor(test_encodings['attention_mask'][i]).unsqueeze(0)
        }
        outputs = pretrained_model(**inputs)
        pred = torch.argmax(outputs.logits, dim=-1)
        predictions.append(pred.item())

# Generate the confusion matrix and classification report
y_true = test_df['label']
y_pred = predictions

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Plot the Confusion Matrix as a heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')
plt.show()

# Classification report
print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Non-Toxic', 'Toxic']))

"""# Dataset: Toxicchat

## load the dataset toxicchat
"""

#  Load the dataset
train_df = pd.read_csv('df_tocxicchat1_train_clean.csv')
test_df = pd.read_csv('df_tocxicchat1_test_clean.csv')

# Display basic data information
print(train_df.head())
print(test_df.head())

"""Split the data into training, validation, and test sets"""

X = train_df['prompt']
y = train_df['label']
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

"""Tokenize the train, validation, and test data"""

tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')
train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=90)
val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=90)
test_encodings = tokenizer(test_df['prompt'].tolist(), truncation=True, padding=True, max_length=90)

"""Create PyTorch datasets"""

train_dataset = Dataset.from_dict({'input_ids': train_encodings['input_ids'],
                                   'attention_mask': train_encodings['attention_mask'],
                                   'labels': y_train.tolist()})
val_dataset = Dataset.from_dict({'input_ids': val_encodings['input_ids'],
                                 'attention_mask': val_encodings['attention_mask'],
                                 'labels': y_val.tolist()})
test_dataset = Dataset.from_dict({'input_ids': test_encodings['input_ids'],
                                  'attention_mask': test_encodings['attention_mask'],
                                  'labels': test_df['label'].tolist()})

"""## Load pretrained DistilBERT model"""

model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)

"""Freeze 50% of the top layers for fine-tuning"""

for param in model.distilbert.transformer.layer[:3]:  # Freezing the first 3 layers out of 6 (50%)
    for p in param.parameters():
        p.requires_grad = False

"""print the model summary"""

import torch
from torchinfo import summary

# Ensure the model is on the correct device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Create a dummy input with the correct tensor type (LongTensor)
dummy_input = torch.randint(0, tokenizer.vocab_size, (1, 40), dtype=torch.long).to(device)

# Print the model summary
summary(model, input_data=dummy_input)

"""set training arguments"""

# Set training arguments
training_args = TrainingArguments(
    output_dir='./results',
    evaluation_strategy="epoch",
    logging_strategy="epoch",  # Enable logging for each epoch to track training loss
    logging_steps=10,  # Log every 10 steps (or adjust as needed)
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir='./logs',
)

"""Define metrics for evaluation"""

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')
    acc = accuracy_score(labels, preds)
    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

"""## Model training"""

# Initialize Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics
)

# Train the model
trainer.train()

"""## Save the model"""

# Save the trained model
model.save_pretrained("DistilBERT_toxicchat_full")

"""Reload the model"""

# Load the saved model (optional step)
loaded_model = DistilBertForSequenceClassification.from_pretrained("DistilBERT_toxicchat_full")

"""## Evaluate the model on the test set and generate results"""

# Evaluate the model on the test set
results = trainer.evaluate(test_dataset)

# Print evaluation results
print(f"Test set results: {results}")

"""Generate confusion matrix and classification report"""

from sklearn.metrics import classification_report, confusion_matrix

y_true = test_df['label']
y_pred = torch.from_numpy(trainer.predict(test_dataset).predictions).argmax(dim=1)

cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Plot the Confusion Matrix as a heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')
plt.show()

print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Non-Toxic', 'Toxic']))

"""## Inference with sample texts"""

# Inference with sample texts
texts = ["Good morning!", "You are a terrible person."]
inference_encodings = tokenizer(texts, truncation=True, padding=True, return_tensors='pt')

# Ensure the model is in evaluation mode
model.eval()

# Perform inference
with torch.no_grad():
    outputs = model(**inference_encodings)
    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)

# Print predictions
labels = ['Non-Toxic', 'Toxic']
predicted_labels = [labels[pred] for pred in predictions]

for text, label in zip(texts, predicted_labels):
    print(f"Text: {text} | Predicted label: {label}")

"""## Hyperparameter Tuning"""

from transformers import Trainer, TrainingArguments
import matplotlib.pyplot as plt

# List of learning rates to try
learning_rates = [5e-5, 3e-5, 2e-5]

# Dictionary to store evaluation results for each learning rate
results_dict = {}

# Reduce the dataset size for faster experimentation
small_train_dataset = train_dataset.select(range(300))  # Select the first 500 samples for training
small_val_dataset = val_dataset.select(range(60))       # Select the first 100 samples for validation
small_test_dataset = test_dataset.select(range(60))     # Select the first 100 samples for testing

for lr in learning_rates:
    print(f"Training with learning rate: {lr}")

    # Adjust the learning rate and number of epochs for quicker training
    training_args = TrainingArguments(
        output_dir='./results',
        evaluation_strategy="epoch",
        save_strategy="epoch",  # Set save strategy to match evaluation strategy
        logging_strategy="steps",
        logging_steps=10,
        learning_rate=lr,
        per_device_train_batch_size=8,
        per_device_eval_batch_size=8,
        num_train_epochs=3,
        weight_decay=0.01,
        logging_dir='./logs',
        load_best_model_at_end=True,  # Still keep this to load the best model
        metric_for_best_model="eval_loss"  # Define the metric to monitor
    )

    # Set up the trainer without early stopping
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=small_train_dataset,
        eval_dataset=small_val_dataset,
        compute_metrics=compute_metrics
    )

    # Train the model
    trainer.train()

    # Evaluate the model
    eval_results = trainer.evaluate(small_test_dataset)

    # Save the evaluation results in the dictionary
    results_dict[lr] = eval_results
    print(f"Results with learning rate {lr}: {eval_results}")

# Plot learning rates vs accuracy
accuracies = [results_dict[lr]['eval_accuracy'] for lr in learning_rates]
plt.plot(learning_rates, accuracies, marker='o')
plt.xlabel('Learning Rate')
plt.ylabel('Accuracy')
plt.title('Accuracy vs Learning Rate')
plt.xscale('log')  # Use log scale for the learning rate
plt.show()

"""## pre-trained model test result without training for comparison"""

# Load the pretrained model
pretrained_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')

# Ensure the model is in evaluation mode
pretrained_model.eval()

# Tokenize the test data
test_encodings = tokenizer(test_df['prompt'].tolist(), truncation=True, padding=True, max_length=16)

# Create the test dataset
test_dataset = Dataset.from_dict({
    'input_ids': test_encodings['input_ids'],
    'attention_mask': test_encodings['attention_mask'],
    'labels': test_df['label'].tolist()
})

# Perform inference on the test dataset using the pretrained model
predictions = []
with torch.no_grad():
    for i in range(len(test_dataset)):
        inputs = {
            'input_ids': torch.tensor(test_encodings['input_ids'][i]).unsqueeze(0),
            'attention_mask': torch.tensor(test_encodings['attention_mask'][i]).unsqueeze(0)
        }
        outputs = pretrained_model(**inputs)
        pred = torch.argmax(outputs.logits, dim=-1)
        predictions.append(pred.item())

# Generate the confusion matrix and classification report
y_true = test_df['label']
y_pred = predictions

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Plot the Confusion Matrix as a heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')
plt.show()

# Classification report
print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Non-Toxic', 'Toxic']))

"""# Dataset: Toxicgen

## load and prepare the dataset Toxicgen
"""

# Load the dataset
train_df = pd.read_csv('df_toxicgen1_train_clean.csv')
test_df = pd.read_csv('df_toxicgen1_test_clean.csv')

# Display basic data information
print(train_df.head())
print(test_df.head())

"""Split the data into training, validation, and test sets"""

X = train_df['prompt']
y = train_df['label']
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

"""Tokenize the train, validation, and test data"""

tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')
train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=40)
val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=40)
test_encodings = tokenizer(test_df['prompt'].tolist(), truncation=True, padding=True, max_length=40)

"""Create PyTorch datasets"""

train_dataset = Dataset.from_dict({'input_ids': train_encodings['input_ids'],
                                   'attention_mask': train_encodings['attention_mask'],
                                   'labels': y_train.tolist()})
val_dataset = Dataset.from_dict({'input_ids': val_encodings['input_ids'],
                                 'attention_mask': val_encodings['attention_mask'],
                                 'labels': y_val.tolist()})
test_dataset = Dataset.from_dict({'input_ids': test_encodings['input_ids'],
                                  'attention_mask': test_encodings['attention_mask'],
                                  'labels': test_df['label'].tolist()})

"""## Load pretrained DistilBERT model"""

model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)

"""Freeze 50% of the top layers for fine-tuning"""

for param in model.distilbert.transformer.layer[:3]:  # Freezing the first 3 layers out of 6 (50%)
    for p in param.parameters():
        p.requires_grad = False

"""print the model summary"""

import torch
from torchinfo import summary

# Ensure the model is on the correct device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Create a dummy input with the correct tensor type (LongTensor)
dummy_input = torch.randint(0, tokenizer.vocab_size, (1, 40), dtype=torch.long).to(device)

# Print the model summary
summary(model, input_data=dummy_input)

"""set training arguments"""

# Set training arguments
training_args = TrainingArguments(
    output_dir='./results',
    evaluation_strategy="epoch",
    logging_strategy="epoch",  # Enable logging for each epoch to track training loss
    logging_steps=10,  # Log every 10 steps (or adjust as needed)
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir='./logs',
)

"""Define metrics for evaluation"""

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')
    acc = accuracy_score(labels, preds)
    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

"""## Model training"""

# Initialize Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics
)

# Train the model
trainer.train()

"""## Save the model"""

# Save the trained model
model.save_pretrained("DistilBERT_Toxicgen_full")

"""Reload the model"""

# Load the saved model (optional step)
loaded_model = DistilBertForSequenceClassification.from_pretrained("DistilBERT_Toxicgen_full")

"""## Evaluate the model on the test set and generate results"""

# Evaluate the model on the test set
results = trainer.evaluate(test_dataset)

# Print evaluation results
print(f"Test set results: {results}")

"""Generate confusion matrix and classification report"""

from sklearn.metrics import classification_report, confusion_matrix

y_true = test_df['label']
y_pred = torch.from_numpy(trainer.predict(test_dataset).predictions).argmax(dim=1)

cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Plot the Confusion Matrix as a heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')
plt.show()

print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Non-Toxic', 'Toxic']))

"""## Inference with sample texts"""

# Inference with sample texts
texts = ["I am very hundsome!", "You are a terrible person."]
inference_encodings = tokenizer(texts, truncation=True, padding=True, return_tensors='pt')

# Ensure the model is in evaluation mode
model.eval()

# Perform inference
with torch.no_grad():
    outputs = model(**inference_encodings)
    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)

# Print predictions
labels = ['Non-Toxic', 'Toxic']
predicted_labels = [labels[pred] for pred in predictions]

for text, label in zip(texts, predicted_labels):
    print(f"Text: {text} | Predicted label: {label}")

"""## Hyperparameter Tuning"""

from transformers import Trainer, TrainingArguments
import matplotlib.pyplot as plt

# List of learning rates to try
learning_rates = [5e-5, 3e-5, 2e-5]

# Dictionary to store evaluation results for each learning rate
results_dict = {}

# Reduce the dataset size for faster experimentation
small_train_dataset = train_dataset.select(range(300))  # Select the first 500 samples for training
small_val_dataset = val_dataset.select(range(60))       # Select the first 100 samples for validation
small_test_dataset = test_dataset.select(range(60))     # Select the first 100 samples for testing

for lr in learning_rates:
    print(f"Training with learning rate: {lr}")

    # Adjust the learning rate and number of epochs for quicker training
    training_args = TrainingArguments(
        output_dir='./results',
        evaluation_strategy="epoch",
        save_strategy="epoch",  # Set save strategy to match evaluation strategy
        logging_strategy="steps",
        logging_steps=10,
        learning_rate=lr,
        per_device_train_batch_size=8,
        per_device_eval_batch_size=8,
        num_train_epochs=3,
        weight_decay=0.01,
        logging_dir='./logs',
        load_best_model_at_end=True,  # Still keep this to load the best model
        metric_for_best_model="eval_loss"  # Define the metric to monitor
    )

    # Set up the trainer without early stopping
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=small_train_dataset,
        eval_dataset=small_val_dataset,
        compute_metrics=compute_metrics
    )

    # Train the model
    trainer.train()

    # Evaluate the model
    eval_results = trainer.evaluate(small_test_dataset)

    # Save the evaluation results in the dictionary
    results_dict[lr] = eval_results
    print(f"Results with learning rate {lr}: {eval_results}")

# Plot learning rates vs accuracy
accuracies = [results_dict[lr]['eval_accuracy'] for lr in learning_rates]
plt.plot(learning_rates, accuracies, marker='o')
plt.xlabel('Learning Rate')
plt.ylabel('Accuracy')
plt.title('Accuracy vs Learning Rate')
plt.xscale('log')  # Use log scale for the learning rate
plt.show()

"""## pre-trained model test result without training for comparison"""

# Load the pretrained model
pretrained_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')

# Ensure the model is in evaluation mode
pretrained_model.eval()

# Tokenize the test data
test_encodings = tokenizer(test_df['prompt'].tolist(), truncation=True, padding=True, max_length=16)

# Create the test dataset
test_dataset = Dataset.from_dict({
    'input_ids': test_encodings['input_ids'],
    'attention_mask': test_encodings['attention_mask'],
    'labels': test_df['label'].tolist()
})

# Perform inference on the test dataset using the pretrained model
predictions = []
with torch.no_grad():
    for i in range(len(test_dataset)):
        inputs = {
            'input_ids': torch.tensor(test_encodings['input_ids'][i]).unsqueeze(0),
            'attention_mask': torch.tensor(test_encodings['attention_mask'][i]).unsqueeze(0)
        }
        outputs = pretrained_model(**inputs)
        pred = torch.argmax(outputs.logits, dim=-1)
        predictions.append(pred.item())

# Generate the confusion matrix and classification report
y_true = test_df['label']
y_pred = predictions

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Plot the Confusion Matrix as a heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')
plt.show()

# Classification report
print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Non-Toxic', 'Toxic']))

"""# Dataset：Ethics

## load and prepare the dataset HateSpeachDetection
"""

# Load the dataset
train_df = pd.read_csv('ds_ethics_commonsense_train_clean.csv')
test_df = pd.read_csv('ds_ethics_commonsense_test_clean.csv')

# Display basic data information
print(train_df.head())
print(test_df.head())

"""Split the data into training, validation, and test sets"""

X = train_df['prompt']
y = train_df['label']
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

"""Tokenize the train, validation, and test data"""

tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')
train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=400)
val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=400)
test_encodings = tokenizer(test_df['prompt'].tolist(), truncation=True, padding=True, max_length=400)

"""Create PyTorch datasets"""

train_dataset = Dataset.from_dict({'input_ids': train_encodings['input_ids'],
                                   'attention_mask': train_encodings['attention_mask'],
                                   'labels': y_train.tolist()})
val_dataset = Dataset.from_dict({'input_ids': val_encodings['input_ids'],
                                 'attention_mask': val_encodings['attention_mask'],
                                 'labels': y_val.tolist()})
test_dataset = Dataset.from_dict({'input_ids': test_encodings['input_ids'],
                                  'attention_mask': test_encodings['attention_mask'],
                                  'labels': test_df['label'].tolist()})

"""## Load pretrained DistilBERT model"""

model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)

"""Freeze 50% of the top layers for fine-tuning"""

for param in model.distilbert.transformer.layer[:3]:  # Freezing the first 3 layers out of 6 (50%)
    for p in param.parameters():
        p.requires_grad = False

"""print the model summary"""

import torch
from torchinfo import summary

# Ensure the model is on the correct device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Create a dummy input with the correct tensor type (LongTensor)
dummy_input = torch.randint(0, tokenizer.vocab_size, (1, 40), dtype=torch.long).to(device)

# Print the model summary
summary(model, input_data=dummy_input)

"""set training arguments"""

# Set training arguments
training_args = TrainingArguments(
    output_dir='./results',
    evaluation_strategy="epoch",
    logging_strategy="epoch",  # Enable logging for each epoch to track training loss
    logging_steps=10,  # Log every 10 steps (or adjust as needed)
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir='./logs',
)

"""Define metrics for evaluation"""

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')
    acc = accuracy_score(labels, preds)
    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

"""## Model training"""

# Initialize Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics
)

# Train the model
trainer.train()

"""## Save the model"""

# Save the trained model
model.save_pretrained("DistilBERT_Ethics_full")

"""Reload the model"""

# Load the saved model (optional step)
loaded_model = DistilBertForSequenceClassification.from_pretrained("DistilBERT_Ethics_full")

"""## Evaluate the model on the test set and generate results"""

# Evaluate the model on the test set
results = trainer.evaluate(test_dataset)

# Print evaluation results
print(f"Test set results: {results}")

"""Generate confusion matrix and classification report"""

from sklearn.metrics import classification_report, confusion_matrix

y_true = test_df['label']
y_pred = torch.from_numpy(trainer.predict(test_dataset).predictions).argmax(dim=1)

cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Plot the Confusion Matrix as a heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')
plt.show()

print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Non-Toxic', 'Toxic']))

"""## Inference with sample texts"""

# Inference with sample texts
texts = ["I am very hundsome!", "You are a terrible person."]
inference_encodings = tokenizer(texts, truncation=True, padding=True, return_tensors='pt')

# Ensure the model is in evaluation mode
model.eval()

# Perform inference
with torch.no_grad():
    outputs = model(**inference_encodings)
    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)

# Print predictions
labels = ['Non-Toxic', 'Toxic']
predicted_labels = [labels[pred] for pred in predictions]

for text, label in zip(texts, predicted_labels):
    print(f"Text: {text} | Predicted label: {label}")

"""## Hyperparameter Tuning"""

from transformers import Trainer, TrainingArguments
import matplotlib.pyplot as plt

# List of learning rates to try
learning_rates = [5e-5, 3e-5, 2e-5]

# Dictionary to store evaluation results for each learning rate
results_dict = {}

# Reduce the dataset size for faster experimentation
small_train_dataset = train_dataset.select(range(300))  # Select the first 300 samples for training
small_val_dataset = val_dataset.select(range(60))       # Select the first 60 samples for validation
small_test_dataset = test_dataset.select(range(60))     # Select the first 60 samples for testing

for lr in learning_rates:
    print(f"Training with learning rate: {lr}")

    # Adjust the learning rate and number of epochs for quicker training
    training_args = TrainingArguments(
        output_dir='./results',
        evaluation_strategy="epoch",
        save_strategy="epoch",  # Set save strategy to match evaluation strategy
        logging_strategy="steps",
        logging_steps=10,
        learning_rate=lr,
        per_device_train_batch_size=8,
        per_device_eval_batch_size=8,
        num_train_epochs=3,
        weight_decay=0.01,
        logging_dir='./logs',
        load_best_model_at_end=True,  # Still keep this to load the best model
        metric_for_best_model="eval_loss"  # Define the metric to monitor
    )

    # Set up the trainer without early stopping
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=small_train_dataset,
        eval_dataset=small_val_dataset,
        compute_metrics=compute_metrics
    )

    # Train the model
    trainer.train()

    # Evaluate the model
    eval_results = trainer.evaluate(small_test_dataset)

    # Save the evaluation results in the dictionary
    results_dict[lr] = eval_results
    print(f"Results with learning rate {lr}: {eval_results}")

# Plot learning rates vs accuracy
accuracies = [results_dict[lr]['eval_accuracy'] for lr in learning_rates]
plt.plot(learning_rates, accuracies, marker='o')
plt.xlabel('Learning Rate')
plt.ylabel('Accuracy')
plt.title('Accuracy vs Learning Rate')
plt.xscale('log')  # Use log scale for the learning rate
plt.show()

"""## pre-trained model test result without training for comparison"""

# Load the pretrained model
pretrained_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')

# Ensure the model is in evaluation mode
pretrained_model.eval()

# Tokenize the test data
test_encodings = tokenizer(test_df['prompt'].tolist(), truncation=True, padding=True, max_length=16)

# Create the test dataset
test_dataset = Dataset.from_dict({
    'input_ids': test_encodings['input_ids'],
    'attention_mask': test_encodings['attention_mask'],
    'labels': test_df['label'].tolist()
})

# Perform inference on the test dataset using the pretrained model
predictions = []
with torch.no_grad():
    for i in range(len(test_dataset)):
        inputs = {
            'input_ids': torch.tensor(test_encodings['input_ids'][i]).unsqueeze(0),
            'attention_mask': torch.tensor(test_encodings['attention_mask'][i]).unsqueeze(0)
        }
        outputs = pretrained_model(**inputs)
        pred = torch.argmax(outputs.logits, dim=-1)
        predictions.append(pred.item())

# Generate the confusion matrix and classification report
y_true = test_df['label']
y_pred = predictions

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Plot the Confusion Matrix as a heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')
plt.show()

# Classification report
print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Non-Toxic', 'Toxic']))